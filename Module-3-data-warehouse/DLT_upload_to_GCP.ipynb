{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aC2QnhmKxpq1"
      },
      "source": [
        "**Please set up your credentials JSON as GCP_CREDENTIALS secrets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UsUZobVduL7l"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "with open(\"gcs.json\", \"r\") as f:\n",
        "    credentials = json.load(f)\n",
        "\n",
        "os.environ[\"DESTINATION__CREDENTIALS\"] = json.dumps(credentials)\n",
        "os.environ[\"BUCKET_URL\"] = \"gs://dezoomcamp_module4_2026\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lYh7r1mTf4uo"
      },
      "outputs": [],
      "source": [
        "import dlt\n",
        "import requests\n",
        "import pandas as pd\n",
        "from dlt.destinations import filesystem\n",
        "from io import BytesIO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76zT1PzAgs7A"
      },
      "source": [
        "Ingesting parquet files to GCS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xya0215jsnsb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-09 09:54:49,516|[WARNING]|61267|8600576192|dlt|validate.py|verify_normalized_table:91|In schema `rides`: The following columns in table 'yellow_tripdata_2020_05_parquet' did not receive any data during this load and therefore could not have their types inferred:\n",
            "  - airport_fee\n",
            "\n",
            "Unless type hints are provided, these columns will not be materialized in the destination.\n",
            "One way to provide type hints is to use the 'columns' argument in the '@dlt.resource' decorator.  For example:\n",
            "\n",
            "@dlt.resource(columns={'airport_fee': {'data_type': 'text'}})\n",
            "\n",
            "2026-02-09 09:54:49,517|[WARNING]|61267|8600576192|dlt|validate.py|verify_normalized_table:91|In schema `rides`: The following columns in table 'yellow_tripdata_2020_04_parquet' did not receive any data during this load and therefore could not have their types inferred:\n",
            "  - airport_fee\n",
            "\n",
            "Unless type hints are provided, these columns will not be materialized in the destination.\n",
            "One way to provide type hints is to use the 'columns' argument in the '@dlt.resource' decorator.  For example:\n",
            "\n",
            "@dlt.resource(columns={'airport_fee': {'data_type': 'text'}})\n",
            "\n",
            "2026-02-09 09:54:49,517|[WARNING]|61267|8600576192|dlt|validate.py|verify_normalized_table:91|In schema `rides`: The following columns in table 'yellow_tripdata_2020_07_parquet' did not receive any data during this load and therefore could not have their types inferred:\n",
            "  - airport_fee\n",
            "\n",
            "Unless type hints are provided, these columns will not be materialized in the destination.\n",
            "One way to provide type hints is to use the 'columns' argument in the '@dlt.resource' decorator.  For example:\n",
            "\n",
            "@dlt.resource(columns={'airport_fee': {'data_type': 'text'}})\n",
            "\n",
            "2026-02-09 09:54:49,517|[WARNING]|61267|8600576192|dlt|validate.py|verify_normalized_table:91|In schema `rides`: The following columns in table 'yellow_tripdata_2020_01_parquet' did not receive any data during this load and therefore could not have their types inferred:\n",
            "  - airport_fee\n",
            "\n",
            "Unless type hints are provided, these columns will not be materialized in the destination.\n",
            "One way to provide type hints is to use the 'columns' argument in the '@dlt.resource' decorator.  For example:\n",
            "\n",
            "@dlt.resource(columns={'airport_fee': {'data_type': 'text'}})\n",
            "\n",
            "2026-02-09 09:54:49,518|[WARNING]|61267|8600576192|dlt|validate.py|verify_normalized_table:91|In schema `rides`: The following columns in table 'yellow_tripdata_2020_02_parquet' did not receive any data during this load and therefore could not have their types inferred:\n",
            "  - airport_fee\n",
            "\n",
            "Unless type hints are provided, these columns will not be materialized in the destination.\n",
            "One way to provide type hints is to use the 'columns' argument in the '@dlt.resource' decorator.  For example:\n",
            "\n",
            "@dlt.resource(columns={'airport_fee': {'data_type': 'text'}})\n",
            "\n",
            "2026-02-09 09:54:49,518|[WARNING]|61267|8600576192|dlt|validate.py|verify_normalized_table:91|In schema `rides`: The following columns in table 'yellow_tripdata_2020_06_parquet' did not receive any data during this load and therefore could not have their types inferred:\n",
            "  - airport_fee\n",
            "\n",
            "Unless type hints are provided, these columns will not be materialized in the destination.\n",
            "One way to provide type hints is to use the 'columns' argument in the '@dlt.resource' decorator.  For example:\n",
            "\n",
            "@dlt.resource(columns={'airport_fee': {'data_type': 'text'}})\n",
            "\n",
            "2026-02-09 09:54:49,518|[WARNING]|61267|8600576192|dlt|validate.py|verify_normalized_table:91|In schema `rides`: The following columns in table 'yellow_tripdata_2020_10_parquet' did not receive any data during this load and therefore could not have their types inferred:\n",
            "  - airport_fee\n",
            "\n",
            "Unless type hints are provided, these columns will not be materialized in the destination.\n",
            "One way to provide type hints is to use the 'columns' argument in the '@dlt.resource' decorator.  For example:\n",
            "\n",
            "@dlt.resource(columns={'airport_fee': {'data_type': 'text'}})\n",
            "\n",
            "2026-02-09 09:54:49,518|[WARNING]|61267|8600576192|dlt|validate.py|verify_normalized_table:91|In schema `rides`: The following columns in table 'yellow_tripdata_2020_03_parquet' did not receive any data during this load and therefore could not have their types inferred:\n",
            "  - airport_fee\n",
            "\n",
            "Unless type hints are provided, these columns will not be materialized in the destination.\n",
            "One way to provide type hints is to use the 'columns' argument in the '@dlt.resource' decorator.  For example:\n",
            "\n",
            "@dlt.resource(columns={'airport_fee': {'data_type': 'text'}})\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline rides_pipeline load step completed in 2 minutes and 32.44 seconds\n",
            "1 load package(s) were loaded to destination filesystem and into dataset rides_dataset\n",
            "The filesystem destination used gs://dezoomcamp_module4_2026 location to store data\n",
            "Load package 1770584083.236244 is LOADED and contains no failed jobs\n"
          ]
        }
      ],
      "source": [
        "# Define a dlt source to download and process Parquet files as resources\n",
        "@dlt.source(name=\"rides\")\n",
        "def download_parquet():\n",
        "    prefix = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata\"\n",
        "    for month in range(1, 13):\n",
        "        month_str = f\"{month:02d}\"\n",
        "        file_name = f\"yellow_tripdata_2020-{month_str}.parquet\"\n",
        "        url = f\"{prefix}_2020-{month_str}.parquet\"\n",
        "        response = requests.get(url)\n",
        "\n",
        "        df = pd.read_parquet(BytesIO(response.content))\n",
        "\n",
        "        # Return the dataframe as a dlt resource for ingestion\n",
        "        yield dlt.resource(df, name=file_name)\n",
        "\n",
        "\n",
        "# Initialize the pipeline\n",
        "pipeline = dlt.pipeline(\n",
        "    pipeline_name=\"rides_pipeline\",\n",
        "    destination=filesystem(layout=\"{schema_name}/{table_name}.{ext}\"),\n",
        "    dataset_name=\"rides_dataset\",\n",
        ")\n",
        "\n",
        "load_info = pipeline.run(download_parquet(), loader_file_format=\"parquet\")\n",
        "\n",
        "# Print the results\n",
        "print(load_info)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0310FT-gy_P"
      },
      "source": [
        "Ingesting data to Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_3K97w1c2v2",
        "outputId": "4b2d26bf-2814-46fa-f80d-7a2e17417a95"
      },
      "outputs": [],
      "source": [
        "# Define a dlt resource to download and process Parquet files as single table\n",
        "@dlt.resource(name=\"rides\", write_disposition=\"replace\")\n",
        "def download_parquet():\n",
        "    prefix = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata'\n",
        "\n",
        "    for month in range(1, 13):\n",
        "        month_str = f\"{month:02d}\"\n",
        "        url = f\"{prefix}_2019-{month_str}.parquet\"\n",
        "        response = requests.get(url)\n",
        "\n",
        "        df = pd.read_parquet(BytesIO(response.content))\n",
        "\n",
        "        yield df\n",
        "\n",
        "\n",
        "# Initialize the pipeline\n",
        "pipeline = dlt.pipeline(\n",
        "    pipeline_name=\"rides_pipeline\",\n",
        "    destination=\"duckdb\",  # Use DuckDB for testing\n",
        "    # destination=\"bigquery\",  # Use BigQuery for production\n",
        "    dataset_name=\"rides_dataset\",\n",
        ")\n",
        "\n",
        "# Run the pipeline to load Parquet data into DuckDB\n",
        "info = pipeline.run(download_parquet)\n",
        "\n",
        "# Print the results\n",
        "print(info)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDcLjzLtooBV",
        "outputId": "74ff2de7-2f2e-41b9-a681-3dc5887f6eed"
      },
      "outputs": [],
      "source": [
        "import duckdb\n",
        "\n",
        "conn = duckdb.connect(f\"{pipeline.pipeline_name}.duckdb\")\n",
        "\n",
        "# Set search path to the dataset\n",
        "conn.sql(f\"SET search_path = '{pipeline.dataset_name}'\")\n",
        "\n",
        "# Describe the dataset to see loaded tables\n",
        "res = conn.sql(\"DESCRIBE\").df()\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVJy8JoerI2P",
        "outputId": "3f8c7fee-a9ee-4fd4-ec75-153ca60bd36f"
      },
      "outputs": [],
      "source": [
        "# provide a resource name to query a table of that name\n",
        "with pipeline.sql_client() as client:\n",
        "    with client.execute_query(f\"SELECT count(1) FROM rides\") as cursor:\n",
        "        data = cursor.df()\n",
        "print(data)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
